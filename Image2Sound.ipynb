{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pydub\n",
    "from pydub.playback import play\n",
    "from skimage import io,color\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "image_path = \"/home/billbrod/Pictures/WFB Brussels.jpg\"\n",
    "import melopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = io.imread(image_path)\n",
    "#We want to use the L*a*b color space instead of RGB because it approximates human perceptual space\n",
    "lab = color.rgb2lab(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def color_df(arr,col,color_name):\n",
    "    df=pd.DataFrame(arr[:,:,col])\n",
    "    df['x'] = df.index\n",
    "    df = pd.melt(df,id_vars='x',var_name='y',value_name=color_name)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L,a,b = [color_df(i,j,k) for i,j,k in zip([lab,lab,lab],[0,1,2],['L','a','b'])]\n",
    "df = pd.merge(L,pd.merge(a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on http://stackoverflow.com/a/29906003, $L \\in [0,100], a,b \\in [-128,127]$. We need to know our min and max in order to find our mappable range.\n",
    "\n",
    "Our color space is three dimensional ($L,a,b$) and for sound to be three dimensional, we're going to use octave ($L$), tone ($a$) and volume ($b$). Make those re-mappable, but we'll see how that works.\n",
    "\n",
    "According to [Wikipedia](https://en.wikipedia.org/wiki/Hearing_range#Humans), humans can hear from 20Hz up to 20kHz and are most sensitive to frequencies between 2kHz and 5kHz.\n",
    "\n",
    "Pydub can be used to generate sounds really well, but it's woefully under-documented. See [this gist](https://gist.github.com/jiaaro/339df443b005e12d6c2a) for a reasonable example (that `output` object can be played, no need to export it!)\n",
    "\n",
    "Melopy.utilities has some useful tools to convert between notes and frequencies.\n",
    "\n",
    "If we need to slice up the color space into cubes of just-noticeable-differences, use `skimage.color.deltaE_ciede2000`. It seems that a delta_e of 1 is the \"just noticeable difference\". Having trouble getting this to work, may need to modify slightly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
